{"version": "1.0", "truncation": null, "padding": null, "added_tokens": [{"id": 0, "special": true, "content": "[endoftext]", "single_word": false, "lstrip": false, "rstrip": false, "normalized": false}], "normalizer": null, "pre_tokenizer": {"type": "Whitespace"}, "post_processor": null, "decoder": null, "model": {"type": "WordLevel", "vocab": {"/": 0, "a": 1, "b": 2, "c": 3, "d": 4, "[endoftext]": 5}, "unk_token": "<unk>"}}